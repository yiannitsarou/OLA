# -*- coding: utf-8 -*-
# Version: 2025-09-06 Clean stable build â€” brand: Î¨Î·Ï†Î¹Î±ÎºÎ® ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎœÎ±Î¸Î·Ï„ÏÎ½ Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï
import sys
import importlib
import importlib.util

# --- Lotus logo beside the title (best-effort search for file) ---
from pathlib import Path as _Path
_logo_candidates = [
    _Path("lotus.png"),
    _Path("lotus_logo.png"),
    _Path("assets/lotus.png"),
    _Path("assets/lotus_logo.png"),
    _Path("static/lotus.png"),
    _Path("static/lotus_logo.png"),
]
_logo_path = next((str(p) for p in _logo_candidates if p.exists()), None)
if _logo_path:
    c1, c2 = st.columns([7,1])
    with c1:
        pass  # title was already rendered above
    with c2:
        st.image(_logo_path, use_column_width=True)
# --- end logo ---

import re, os, json, importlib.util, datetime as dt, math, base64, unicodedata
from pathlib import Path
from io import BytesIO

ROOT = Path(__file__).parent.resolve()

import streamlit as st
import pandas as pd

# --- Embedded logo fallback (base64) - ÎšÎ•ÎÎŸ Î³Î¹Î± Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ¿ Î±ÏÏ‡ÎµÎ¯Î¿ ---
LOGO_B64 = ""  # Î˜Î± Î´Î¹Î±Î²Î¬Î¶ÎµÎ¹ Î±Ï€ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿
LOGO_MIME = "image/png"

def _get_logo_bytes():
    """Return logo bytes: from file path if available, else from embedded base64."""
    path = None
    try:
        path = _find_logo_path()
    except Exception:
        path = None
    if path:
        try:
            return Path(path).read_bytes()
        except Exception:
            pass
    if LOGO_B64:
        try:
            return base64.b64decode(LOGO_B64)
        except Exception:
            return None
    return None

def _inject_floating_logo(width_px=62):
    """Render a floating logo at bottom-right that stays on screen while scrolling."""
    try:
        if st.session_state.get("auth_ok") and st.session_state.get("accepted_terms"):
            return
    except Exception:
        pass
    data = _get_logo_bytes()
    if not data:
        return
    b64 = base64.b64encode(data).decode('utf-8')
    mime = LOGO_MIME

    st.markdown(f"""
<style>
#floating-logo {{
  position: fixed;
  left: 285px;
  bottom: 16px;
  z-index: 9999;
  opacity: 0.95;
  pointer-events: none;
}}
#floating-logo img {{
  width: {width_px}px;
  height: auto;
  filter: drop-shadow(0 1px 2px rgba(0,0,0,0.20));
  opacity: 0.92;
}}
@media (max-width: 768px) {{
  #floating-logo img {{ width: {max(72, int(0.85*width_px))}px; }}
  #floating-logo {{ left: 285px; bottom: 12px; }}
}}
</style>
<div id="floating-logo">
  <img src="data:{mime};base64,{b64}" alt="logo" />
</div>
""", unsafe_allow_html=True)

from PIL import Image, ImageDraw, ImageFont

def _find_logo_path():
    from pathlib import Path as _P
    here = _P(__file__).parent
    candidates = [
        "logo_sidebar_preview_selected.png",
        "logo_lotus_lilac_sidebar100.png",
        "logo_lotus_lilac_original.png",
        "logo_lotus_lilac_header180.png",
        "logo_violet_white.png",
        "logo.png",
        "assets/logo.png",
        "lotus_appicon_white_1024.png",
    ]
    search_bases = [here, here / "assets", _P("/mnt/data")]
    for base in search_bases:
        for c in candidates:
            p = base / c
            if p.exists():
                return str(p)
    for base in search_bases:
        for p in base.glob("lotus*.png"):
            return str(p)
    return None

def _make_logo_with_overlay(img_path, width=140, text="Â«No man is an islandÂ»"):
    try:
        im = Image.open(img_path).convert("RGBA")
    except Exception:
        return None
    scale = width / im.width
    target_h = int(im.height * scale)
    im = im.resize((width, target_h), Image.Resampling.LANCZOS if hasattr(Image, "Resampling") else Image.LANCZOS)
    draw = ImageDraw.Draw(im, "RGBA")
    font_candidates = [
        ("DejaVuSans.ttf", 20),
        ("Arial.ttf", 20),
        ("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 20),
    ]
    font = None
    for fname, fsize in font_candidates:
        try:
            font = ImageFont.truetype(fname, fsize)
            break
        except Exception:
            continue
    if font is None:
        font = ImageFont.load_default()
    max_w = int(width * 0.92)
    fsize = getattr(font, "size", 18)
    while True:
        bbox = draw.textbbox((0,0), text, font=font, stroke_width=2)
        tw, th = bbox[2], bbox[3]
        if tw <= max_w or fsize <= 11:
            break
        fsize -= 1
        try:
            font = ImageFont.truetype(font.path, fsize) if hasattr(font, "path") else ImageFont.truetype("DejaVuSans.ttf", fsize)
        except Exception:
            font = ImageFont.truetype("DejaVuSans.ttf", fsize)
    bbox = draw.textbbox((0,0), text, font=font, stroke_width=2)
    tw, th = bbox[2], bbox[3]
    tx = max(0, (width - tw)//2)
    ty = target_h - th - 6
    draw.text((tx, ty), text, font=font, fill=(255,255,255,255), stroke_width=2, stroke_fill=(0,0,0,220))
    return im

_logo_path = _find_logo_path()
_logo_img = None
if _logo_path:
    try:
        _logo_img = Image.open(_logo_path)
    except Exception:
        _logo_img = None

_logo_bytes = _get_logo_bytes()
_logo_img = None
if _logo_bytes:
    try:
        _logo_img = Image.open(BytesIO(_logo_bytes))
    except Exception:
        _logo_img = None

st.set_page_config(page_title="Î¨Î·Ï†Î¹Î±ÎºÎ® ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎœÎ±Î¸Î·Ï„ÏÎ½ Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï", page_icon=_logo_img if _logo_img else "ğŸ§©", layout="wide")

st.title("Î¨Î·Ï†Î¹Î±ÎºÎ® ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎœÎ±Î¸Î·Ï„ÏÎ½ Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï")

try:
    _logo_inline_bytes = _get_logo_bytes()
    _logo_inline_b64 = base64.b64encode(_logo_inline_bytes).decode("ascii") if _logo_inline_bytes else ""
except Exception:
    _logo_inline_b64 = ""

st.markdown(f"""
<div style="display:flex; align-items:center; gap:8px; opacity:0.85;">
  <span>Â«Î“Î¹Î± Î¼Î¹Î± Ï€Î±Î¹Î´ÎµÎ¯Î± Ï€Î¿Ï… Î²Î»Î­Ï€ÎµÎ¹ Ï„Î¿ Ï†Ï‰Ï‚ ÏƒÎµ ÏŒÎ»Î± Ï„Î± Ï€Î±Î¹Î´Î¹Î¬Â»</span>
  <img src="data:image/png;base64,{_logo_inline_b64}" alt="lotus" style="width:18px; height:auto; margin-top:-2px; " />
</div>
""", unsafe_allow_html=True)

try:
    _auth = bool(st.session_state.get("auth_ok", False))
    _terms = bool(st.session_state.get("accepted_terms", False))
except Exception:
    _auth, _terms = (False, False)
if not (_auth and _terms):
    _inject_floating_logo(width_px=62)


def _load_module(name: str, file_path: Path):
    """Load a local module by name, ensuring its folder is on sys.path.
    We avoid exec_module here because dataclasses/typing may rely on
    sys.modules[name] being registered during import.
    """
    parent = str(file_path.parent)
    if parent not in sys.path:
        sys.path.insert(0, parent)
    # Remove any stale module
    if name in sys.modules:
        del sys.modules[name]
    return importlib.import_module(name)
def _read_file_bytes(path: Path) -> bytes:
    with open(path, "rb") as f:
        return f.read()

def _timestamped(base: str, ext: str) -> str:
    ts = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
    import re as _re
    safe = _re.sub(r"[^A-Za-z0-9_\-\.]+", "_", base)
    return f"{safe}_{ts}{ext}"

def _find_latest_step6():
    try:
        candidates = sorted((p for p in ROOT.glob("STEP1_6_PER_SCENARIO*.xlsx") if p.is_file()),
                            key=lambda p: p.stat().st_mtime,
                            reverse=True)
        return candidates[0] if candidates else None
    except Exception:
        return None

def _check_required_files(paths):
    missing = [str(p) for p in paths if not p.exists()]
    return missing

def _inject_logo(logo_bytes: bytes, width_px: int = 140, mime: str = "image/png"):
    b64 = base64.b64encode(logo_bytes).decode("ascii")
    html = f"""
    <div style="position: fixed; bottom: 38px; right: 38px; z-index: 1000;">
        <img src="data:{mime};base64,{b64}" style="width:{width_px}px; height:auto; opacity:0.95; border-radius:12px;" />
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

def _restart_app():
    for k in list(st.session_state.keys()):
        if k.startswith("uploader_") or k in ("auth_ok","accepted_terms","app_enabled","last_final_path"):
            try:
                del st.session_state[k]
            except Exception:
                pass
    try:
        st.cache_data.clear()
    except Exception:
        pass
    try:
        st.cache_resource.clear()
    except Exception:
        pass
    try:
        for pat in ("STEP7_FINAL_SCENARIO*.xlsx", "STEP1_6_PER_SCENARIO*.xlsx", "INPUT_STEP1*.xlsx", "STEP8_*.xlsx"):
            for f in ROOT.glob(pat):
                try:
                    f.unlink()
                except Exception:
                    pass
    except Exception:
        pass
    st.rerun()

def _terms_md():
    return """
**Î¥Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÎ® Î‘Ï€Î¿Î´Î¿Ï‡Î® ÎŒÏÏ‰Î½ Î§ÏÎ®ÏƒÎ·Ï‚**  
Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î´Î·Î»ÏÎ½ÎµÏ„Îµ ÏŒÏ„Î¹:  
- Î”ÎµÎ½ Ï„ÏÎ¿Ï€Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Îµ Ï„Î· Î»Î¿Î³Î¹ÎºÎ® Ï„Ï‰Î½ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½ ÎºÎ±Î¹ Î´ÎµÎ½ Î±Î½Î±Î´Î¹Î±Î½Î­Î¼ÎµÏ„Îµ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Ï‡Ï‰ÏÎ¯Ï‚ Î¬Î´ÎµÎ¹Î±.  
- Î‘Î½Î±Î»Î±Î¼Î²Î¬Î½ÎµÏ„Îµ Ï„Î·Î½ ÎµÏ…Î¸ÏÎ½Î· Î³Î¹Î± Ï„Î·Î½ Î¿ÏÎ¸ÏŒÏ„Î·Ï„Î± Ï„Ï‰Î½ ÎµÎ¹ÏƒÎ±Î³ÏŒÎ¼ÎµÎ½Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.  
- Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Ï€Î±ÏÎ­Ï‡ÎµÏ„Î±Î¹ Â«Ï‰Ï‚ Î­Ï‡ÎµÎ¹Â», Ï‡Ï‰ÏÎ¯Ï‚ ÎµÎ³Î³ÏÎ·ÏƒÎ· Î³Î¹Î± Î¿Ï€Î¿Î¹Î±Î´Î®Ï€Î¿Ï„Îµ Ï‡ÏÎ®ÏƒÎ·.  

**Î Î½ÎµÏ…Î¼Î±Ï„Î¹ÎºÎ¬ Î”Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î± & ÎÎ¿Î¼Î¹ÎºÎ® Î ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î±**  
Â© 2025 Î“Î¹Î±Î½Î½Î¯Ï„ÏƒÎ±ÏÎ¿Ï… Î Î±Î½Î±Î³Î¹ÏÏ„Î± â€” ÏŒÎ»Î± Ï„Î± Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î± Î´Î¹Î±Ï„Î·ÏÎ¿ÏÎ½Ï„Î±Î¹.  
Î“Î¹Î± Î¬Î´ÎµÎ¹Î± Ï‡ÏÎ®ÏƒÎ·Ï‚/ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚: *panayiotayiannitsarou@gmail.com*.
"""

def _story_md():
    return """
**Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î±Ï…Ï„Î® Î³ÎµÎ½Î½Î®Î¸Î·ÎºÎµ Î±Ï€ÏŒ Î¼Î¹Î± ÎµÏƒÏ‰Ï„ÎµÏÎ¹ÎºÎ® Î±Î½Î¬Î³ÎºÎ·:** Î½Î± Î¸Ï…Î¼Î¯ÏƒÎµÎ¹ ÏŒÏ„Î¹ **ÎºÎ±Î½Î­Î½Î± Ï€Î±Î¹Î´Î¯ Î´ÎµÎ½ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î¼Î­Î½ÎµÎ¹ ÏƒÏ„Î¿ Ï€ÎµÏÎ¹Î¸ÏÏÎ¹Î¿**. Î¤Î¿ Ï€Î±Î¹Î´Î¯ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î±Ï€Î»ÏÏ‚ Î­Î½Î± ÏŒÎ½Î¿Î¼Î± ÏƒÎµ Î»Î¯ÏƒÏ„Î±. Î•Î¯Î½Î±Î¹ Ï€Î±ÏÎ¿Ï…ÏƒÎ¯Î±, ÏˆÏ…Ï‡Î®, Î¼Î­Î»Î¿Ï‚ Î¼Î¹Î±Ï‚ Î¿Î¼Î¬Î´Î±Ï‚. ÎœÎ¹Î± Î±Ï€ÎµÏÎ¯ÏƒÎºÎµÏ€Ï„Î· ÎºÎ±Ï„Î±Î½Î¿Î¼Î® Î® Î­Î½Î±Ï‚ Î»Î±Î½Î¸Î±ÏƒÎ¼Î­Î½Î¿Ï‚ Ï€Î±Î¹Î´Î±Î³Ï‰Î³Î¹ÎºÏŒÏ‚ Ï‡ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï„Î±ÏÎ¬Î¾ÎµÎ¹ Ï„Î·Î½ ÎµÏ…Î¸ÏÎ±Ï…ÏƒÏ„Î· ÏˆÏ…Ï‡Î¹ÎºÎ® Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± ÎµÎ½ÏŒÏ‚ Ï€Î±Î¹Î´Î¹Î¿Ï â€” ÎºÎ±Î¹ Î¼Î±Î¶Î¯ Ï„Î·Ï‚, Ï„Î·Î½ Î·ÏÎµÎ¼Î¯Î± Î¼Î¹Î±Ï‚ Î¿Î¹ÎºÎ¿Î³Î­Î½ÎµÎ¹Î±Ï‚.

ÎŒÏ€Ï‰Ï‚ Î­Î³ÏÎ±ÏˆÎµ Î¿ John Donne, Â«ÎšÎ±Î½Î­Î½Î±Ï‚ Î¬Î½Î¸ÏÏ‰Ï€Î¿Ï‚ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î½Î·ÏƒÎ¯Â» ("No man is an island")Â¹: ÎºÎ±Î½ÎµÎ¯Ï‚ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î±Ï€Î¿Î¼Î¿Î½Ï‰Î¼Î­Î½Î¿Ï‚Â· ÏŒ,Ï„Î¹ ÏƒÏ…Î¼Î²Î±Î¯Î½ÎµÎ¹ ÏƒÎµ Î­Î½Î±Î½, Î±Ï†Î¿ÏÎ¬ ÏŒÎ»Î¿Ï…Ï‚. Î•Î¯Î¼Î±ÏƒÏ„Îµ Î¼Î­ÏÎ¿Ï‚ ÎµÎ½ÏŒÏ‚ ÎµÏ…ÏÏÏ„ÎµÏÎ¿Ï… ÏƒÏ…Î½ÏŒÎ»Î¿Ï…Â· Î· Î¼Î¿Î¯ÏÎ±, Î· Ï‡Î±ÏÎ¬ Î® Î¿ Ï€ÏŒÎ½Î¿Ï‚ Ï„Î¿Ï… Î¬Î»Î»Î¿Ï… Î¼Î±Ï‚ Î±Î³Î³Î¯Î¶Î¿Ï…Î½, Î³Î¹Î±Ï„Î¯ ÎµÎ¯Î¼Î±ÏƒÏ„Îµ ÏƒÏ…Î½Î´ÎµÎ´ÎµÎ¼Î­Î½Î¿Î¹.

Î£Ï„Î¿ ÏƒÏ‡Î¿Î»ÎµÎ¯Î¿ Î±Ï…Ï„ÏŒ Î³Î¯Î½ÎµÏ„Î±Î¹ Ï€ÏÎ¬Î¾Î·: ÎºÎ¬Î¸Îµ Î±Ï€ÏŒÏ†Î±ÏƒÎ· ÎµÎ¯Î½Î±Î¹ Ï€ÏÎ¬Î¾Î· Ï€Î±Î¹Î´Î±Î³Ï‰Î³Î¹ÎºÎ®Ï‚ ÎµÏ…Î¸ÏÎ½Î·Ï‚. ÎˆÎ½Î± Ï€ÏÏŒÎ³ÏÎ±Î¼Î¼Î± ÎºÎ±Ï„Î±Î½Î¿Î¼Î®Ï‚ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Ï€Î¿Ï„Î­ Î±Ï€Î»ÏÏ‚ Î­Î½Î± Ï„ÎµÏ‡Î½Î¹ÎºÏŒ ÎµÏÎ³Î±Î»ÎµÎ¯Î¿. Î•Î¯Î½Î±Î¹ **Î­ÎºÏ†ÏÎ±ÏƒÎ· Ï€Î±Î¹Î´Î±Î³Ï‰Î³Î¹ÎºÎ®Ï‚ ÎµÏ…Î¸ÏÎ½Î·Ï‚** ÎºÎ±Î¹ **ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÎºÎ®Ï‚ ÎµÏ…Î±Î¹ÏƒÎ¸Î·ÏƒÎ¯Î±Ï‚**. Î”ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î¼ÏŒÎ½Î¿ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚Â· ÎµÎ¯Î½Î±Î¹ Î­ÎºÏ†ÏÎ±ÏƒÎ· ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÎºÎ®Ï‚ ÎµÏ…Î±Î¹ÏƒÎ¸Î·ÏƒÎ¯Î±Ï‚ ÎºÎ±Î¹ ÎµÎ¼Ï€Î¹ÏƒÏ„Î¿ÏƒÏÎ½Î·Ï‚ ÏƒÏ„Î¿ Î¼Î­Î»Î»Î¿Î½ â€” Ï„Ï‰Î½ Ï€Î±Î¹Î´Î¹ÏÎ½ ÎºÎ±Î¹ Ï„Î·Ï‚ ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±Ï‚.

*Â¹ Î— Ï†ÏÎ¬ÏƒÎ· Ï…Ï€Î¿Î³ÏÎ±Î¼Î¼Î¯Î¶ÎµÎ¹ ÏŒÏ„Î¹ ÎºÎ±Î½ÎµÎ¯Ï‚ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Ï€Î»Î®ÏÏ‰Ï‚ Î±Î½ÎµÎ¾Î¬ÏÏ„Î·Ï„Î¿Ï‚.*

â€” ÎœÎµ ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ·,  
**Î“Î¹Î±Î½Î½Î¯Ï„ÏƒÎ±ÏÎ¿Ï… Î Î±Î½Î±Î³Î¹ÏÏ„Î±**

**Î‘Ï€ÏŒÏƒÏ€Î±ÏƒÎ¼Î± Î±Ï€ÏŒ Ï„Î¿Î½ John Donne**
> No man is an island,
> Entire of itself;
> Every man is a piece of the continent,
> A part of the main.
> If a clod be washed away by the sea,
> Europe is the less,
> As well as if a promontory were,
> As well as if a manor of thy friend's
> Or of thine own were.
> Any man's death diminishes me,
> Because I am involved in mankind.
> And therefore never send to know for whom the bell tolls;
> It tolls for thee.

â€” *John Donne*
"""

REQUIRED = [
    ROOT / "export_step1_6_per_scenario.py",
    ROOT / "step1_immutable_ALLINONE.py",
    ROOT / "step_2_helpers_FIXED.py",
    ROOT / "step_2_zoiroi_idiaterotites_FIXED_v3_PATCHED.py",
    ROOT / "step3_amivaia_filia_FIXED.py",
    ROOT / "step4_corrected.py",
    ROOT / "step5_enhanced.py",
    ROOT / "step6_compliant.py",
    ROOT / "step7_fixed_final.py",
    ROOT / "step8_fixed_final.py",  # ÎÎ•ÎŸ
]

with st.sidebar:
    st.header("ğŸ” Î ÏÏŒÏƒÎ²Î±ÏƒÎ· & Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚")
    
    if "auth_ok" not in st.session_state:
        st.session_state.auth_ok = False
    pwd = st.text_input("ÎšÏ‰Î´Î¹ÎºÏŒÏ‚ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·Ï‚", type="password")
    if pwd:
        st.session_state.auth_ok = (pwd.strip() == "katanomi2025")
        if not st.session_state.auth_ok:
            st.error("Î›Î±Î½Î¸Î±ÏƒÎ¼Î­Î½Î¿Ï‚ ÎºÏ‰Î´Î¹ÎºÏŒÏ‚.")
    
    if "accepted_terms" not in st.session_state:
        st.session_state.accepted_terms = False
    st.session_state.accepted_terms = st.checkbox(
        "âœ… Î‘Ï€Î¿Î´Î­Ï‡Î¿Î¼Î±Î¹ Ï„Î¿Ï…Ï‚ ÎŒÏÎ¿Ï…Ï‚ Î§ÏÎ®ÏƒÎ·Ï‚",
        value=st.session_state.get("accepted_terms", False)
    )
    
    with st.expander("ğŸ“„ ÎŒÏÎ¿Î¹ Î§ÏÎ®ÏƒÎ·Ï‚ & Î Î½ÎµÏ…Î¼Î±Ï„Î¹ÎºÎ¬ Î”Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î±", expanded=False):
        st.markdown(_terms_md())
    
    if "show_story" not in st.session_state:
        st.session_state.show_story = False
    if st.button("ğŸ§­ Î— Î™ÏƒÏ„Î¿ÏÎ¯Î± Ï„Î·Ï‚ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚ & Î Î·Î³Î® ÎˆÎ¼Ï€Î½ÎµÏ…ÏƒÎ·Ï‚", use_container_width=True, key="btn_story"):
        st.session_state.show_story = not st.session_state.show_story
    if st.session_state.show_story:
        st.markdown(_story_md())

st.divider()

if not st.session_state.auth_ok:
    st.warning("ğŸ” Î•Î¹ÏƒÎ¬Î³ÎµÏ„Îµ Ï„Î¿Î½ ÏƒÏ‰ÏƒÏ„ÏŒ ÎºÏ‰Î´Î¹ÎºÏŒ Î³Î¹Î± Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· (Î±ÏÎ¹ÏƒÏ„ÎµÏÎ¬).")
    st.stop()

if not st.session_state.accepted_terms:
    st.warning("âœ… Î“Î¹Î± Î½Î± ÏƒÏ…Î½ÎµÏ‡Î¯ÏƒÎµÏ„Îµ, Î±Ï€Î¿Î´ÎµÏ‡Î¸ÎµÎ¯Ï„Îµ Ï„Î¿Ï…Ï‚ ÎŒÏÎ¿Ï…Ï‚ Î§ÏÎ®ÏƒÎ·Ï‚ (Î±ÏÎ¹ÏƒÏ„ÎµÏÎ¬).")
    st.stop()

st.subheader("ğŸ“¦ ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±ÏÏ‡ÎµÎ¯Ï‰Î½")
missing = _check_required_files(REQUIRED)
if missing:
    st.error("âŒ Î›ÎµÎ¯Ï€Î¿Ï…Î½ Î±ÏÏ‡ÎµÎ¯Î±:\n" + "\n".join(f"- {m}" for m in missing))
else:
    st.success("âœ… ÎŒÎ»Î± Ï„Î± Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Î²ÏÎ­Î¸Î·ÎºÎ±Î½.")

st.divider()

st.header("ğŸš€ Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ÎšÎ±Ï„Î±Î½Î¿Î¼Î®Ï‚")

up_all = st.file_uploader("Î‘Î½Î­Î²Î±ÏƒÎµ Î±ÏÏ‡Î¹ÎºÏŒ Excel (Î³Î¹Î± 1â†’7)", type=["xlsx"], key="uploader_all")
colA, colB, colC = st.columns([1,1,1])
with colA:
    pick_step4_all = st.selectbox("ÎšÎ±Î½ÏŒÎ½Î±Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ ÏƒÏ„Î¿ Î’Î®Î¼Î± 4", ["best", "first", "strict"], index=0, key="pick_all")
with colB:
    final_name_all = st.text_input("ÎŒÎ½Î¿Î¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï… Î¤ÎµÎ»Î¹ÎºÎ¿Ï Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î¿Ï‚", value=_timestamped("STEP7_FINAL_SCENARIO", ".xlsx"))
with colC:
    if up_all is not None:
        try:
            df_preview = pd.read_excel(up_all, sheet_name=0)
            N = df_preview.shape[0]
            min_classes = max(2, math.ceil(N/25)) if N else 0
            st.metric("ÎœÎ±Î¸Î·Ï„Î­Ï‚ / Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î± Ï„Î¼Î®Î¼Î±Ï„Î±", f"{N} / {min_classes}")
        except Exception:
            st.caption("Î”ÎµÎ½ Î®Ï„Î±Î½ Î´Ï…Î½Î±Ï„Î® Î· Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· Î³Î¹Î± Ï€ÏÎ¿ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·.")

if st.button("ğŸš€ Î•ÎšÎ¤Î•Î›Î•Î£Î— ÎšÎ‘Î¤Î‘ÎÎŸÎœÎ—Î£", type="primary", use_container_width=True):
    if missing:
        st.error("Î”ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Ï…Î½Î±Ï„Î® Î· ÎµÎºÏ„Î­Î»ÎµÏƒÎ·: Î»ÎµÎ¯Ï€Î¿Ï…Î½ modules.")
    elif up_all is None:
        st.warning("Î ÏÏÏ„Î± Î±Î½Î­Î²Î±ÏƒÎµ Î­Î½Î± Excel.")
    else:
        try:
            input_path = ROOT / _timestamped("INPUT_STEP1", ".xlsx")
            with open(input_path, "wb") as f:
                f.write(up_all.getbuffer())

            m = _load_module("export_step1_6_per_scenario", ROOT / "export_step1_6_per_scenario.py")
            s7 = _load_module("step7_fixed_final", ROOT / "step7_fixed_final.py")

            step6_path = ROOT / _timestamped("STEP1_6_PER_SCENARIO", ".xlsx")
            with st.spinner("Î¤ÏÎ­Ï‡Î¿Ï…Î½ Ï„Î± Î’Î®Î¼Î±Ï„Î± 1â†’6..."):
                m.build_step1_6_per_scenario(str(input_path), str(step6_path), pick_step4=pick_step4_all)

            with st.spinner("Î¤ÏÎ­Ï‡ÎµÎ¹ Ï„Î¿ Î’Î®Î¼Î± 7..."):
                xls = pd.ExcelFile(step6_path)
                sheet_names = [s for s in xls.sheet_names if s != "Î£ÏÎ½Î¿ÏˆÎ·"]
                if not sheet_names:
                    st.error("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ sheets ÏƒÎµÎ½Î±ÏÎ¯Ï‰Î½ (ÎµÎºÏ„ÏŒÏ‚ Î±Ï€ÏŒ 'Î£ÏÎ½Î¿ÏˆÎ·').")
                else:
                    candidates = []
                    import random as _rnd
                    for sheet in sheet_names:
                        df_sheet = pd.read_excel(step6_path, sheet_name=sheet)
                        scen_cols = [c for c in df_sheet.columns if re.match(r"^Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_\d+$", str(c))]
                        for col in scen_cols:
                            s = s7.score_one_scenario(df_sheet, col)
                            s["sheet"] = sheet
                            candidates.append(s)

                    if not candidates:
                        st.error("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÎµÎ½Î¬ÏÎ¹Î± Î’Î®Î¼Î±Ï„Î¿Ï‚ 6 ÏƒÎµ ÎºÎ±Î½Î­Î½Î± Ï†ÏÎ»Î»Î¿.")
                    else:
                        pool_sorted = sorted(
                            candidates,
                            key=lambda s: (
                                int(s["total_score"]),
                                int(s.get("broken_friendships", 0)),
                                int(s["diff_population"]),
                                int(s["diff_gender_total"]),
                                int(s["diff_greek"]),
                                str(s["scenario_col"]),
                            )
                        )

                        head = pool_sorted[0]
                        ties = [s for s in pool_sorted if (
                            int(s["total_score"]) == int(head["total_score"]) and
                            int(s.get("broken_friendships", 0)) == int(head.get("broken_friendships", 0)) and
                            int(s["diff_population"]) == int(head["diff_population"]) and
                            int(s["diff_gender_total"]) == int(head["diff_gender_total"]) and
                            int(s["diff_greek"]) == int(head["diff_greek"])
                        )]

                        _rnd.seed(42)
                        best = _rnd.choice(ties) if len(ties) > 1 else head

                        winning_sheet = best["sheet"]
                        winning_col = best["scenario_col"]
                        final_out = ROOT / final_name_all

                        full_df = pd.read_excel(step6_path, sheet_name=winning_sheet).copy()
                        with pd.ExcelWriter(final_out, engine="xlsxwriter") as w:
                            labels = sorted(
                                [str(v) for v in full_df[winning_col].dropna().unique() if re.match(r"^Î‘\d+$", str(v))],
                                key=lambda x: int(re.search(r"\d+", x).group(0))
                            )
                            for lab in labels:
                                sub = full_df.loc[full_df[winning_col] == lab, ["ÎŸÎÎŸÎœÎ‘", winning_col]].copy()
                                sub = sub.rename(columns={winning_col: "Î¤ÎœÎ—ÎœÎ‘"})
                                sub.to_excel(w, index=False, sheet_name=str(lab))

                        st.session_state["last_final_path"] = str(final_out.resolve())
                        st.session_state["last_step6_path"] = str(step6_path)
                        st.session_state["last_winning_sheet"] = str(winning_sheet)
                        st.session_state["last_winning_col"] = str(winning_col)
                        st.session_state["last_input_path"] = str(input_path)  # ÎÎ•ÎŸ: Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· input

                        st.success(f"âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ. ÎÎ¹ÎºÎ·Ï„Î®Ï‚: Ï†ÏÎ»Î»Î¿ {winning_sheet} â€” ÏƒÏ„Î®Î»Î· {winning_col}")
                        st.download_button(
                            "â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ Î¤ÎµÎ»Î¹ÎºÏŒ Î‘Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î± (1â†’7)",
                            data=_read_file_bytes(final_out),
                            file_name=final_out.name,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
                        st.caption("â„¹ï¸ Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÎºÎ±Î¹ Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ **Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±** Î±Ï€ÏŒ Ï„Î± Â«ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬Â».")
        except Exception as e:
            st.exception(e)

st.divider()

def _find_latest_final_path() -> Path | None:
    p = st.session_state.get("last_final_path")
    if p and Path(p).exists():
        return Path(p)
    return None

xl = None
st.header("ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Ï„Î¼Î·Î¼Î¬Ï„Ï‰Î½")

final_path = _find_latest_final_path()
if not final_path:
    st.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î±ÏÏ‡ÎµÎ¯Î¿ Î’Î®Î¼Î±Ï„Î¿Ï‚ 7. Î ÏÏÏ„Î± Ï„ÏÎ­Î¾Îµ Â«Î•ÎšÎ¤Î•Î›Î•Î£Î— ÎšÎ‘Î¤Î‘ÎÎŸÎœÎ—Î£Â».")
else:
    try:
        xl = pd.ExcelFile(final_path)
        sheets = xl.sheet_names
        st.success(f"âœ… Î’ÏÎ­Î¸Î·ÎºÎµ: **{final_path.name}** | Sheets: {', '.join(sheets)}")
    except Exception as e:
        xl = None
        st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚: {e}")

if xl is not None:
    used_df = None
    if "FINAL_SCENARIO" in sheets:
        used_df = xl.parse("FINAL_SCENARIO")
        scen_cols = [c for c in used_df.columns if re.match(r"^Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_\d+$", str(c))]
        if len(scen_cols) != 1:
            st.error("âŒ Î‘Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ **Î±ÎºÏÎ¹Î²ÏÏ‚ Î¼Î¯Î±** ÏƒÏ„Î®Î»Î· `Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_N` ÏƒÏ„Î¿ FINAL_SCENARIO.")
            used_df = None
        else:
            used_df["Î¤ÎœÎ—ÎœÎ‘"] = used_df[scen_cols[0]].astype(str).str.strip()

    if used_df is None:
        class_sheets = [s for s in sheets if re.match(r"^Î‘\d+$", str(s))]
        if not class_sheets:
            st.error("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î¿ÏÏ„Îµ 'FINAL_SCENARIO' Î¿ÏÏ„Îµ Ï†ÏÎ»Î»Î± Ï„ÏÏ€Î¿Ï… Î‘1, Î‘2, ...")
        else:
            frames = []
            for sh in class_sheets:
                df_sh = xl.parse(sh).copy()
                if "Î¤ÎœÎ—ÎœÎ‘" not in df_sh.columns:
                    df_sh["Î¤ÎœÎ—ÎœÎ‘"] = str(sh)
                keep_cols = [c for c in ["ÎŸÎÎŸÎœÎ‘","Î¤ÎœÎ—ÎœÎ‘"] if c in df_sh.columns]
                frames.append(df_sh[keep_cols])
            used_df = pd.concat(frames, axis=0, ignore_index=True)

            step6_path = st.session_state.get("last_step6_path")
            win_sheet = st.session_state.get("last_winning_sheet")
            win_col = st.session_state.get("last_winning_col")
            if step6_path and win_sheet and Path(step6_path).exists():
                try:
                    base_df = pd.read_excel(step6_path, sheet_name=win_sheet).copy()
                    def _canon_name_for_merge(s: str) -> str:
                        s = unicodedata.normalize("NFKC", str(s)).strip().lower()
                        s = re.sub(r"\s+", " ", s)
                        return s
                    used_df["__C"] = used_df["ÎŸÎÎŸÎœÎ‘"].map(_canon_name_for_merge)
                    if "ÎŸÎÎŸÎœÎ‘" in base_df.columns:
                        base_df["__C"] = base_df["ÎŸÎÎŸÎœÎ‘"].map(_canon_name_for_merge)
                        class_by_name = dict(zip(used_df["__C"], used_df["Î¤ÎœÎ—ÎœÎ‘"]))
                        base_df["Î¤ÎœÎ—ÎœÎ‘"] = base_df["__C"].map(class_by_name)
                        used_df = base_df[base_df["Î¤ÎœÎ—ÎœÎ‘"].notna()].drop(columns=["__C"])
                except Exception as _e:
                    st.info(f"âš ï¸ Î”ÎµÎ½ ÎºÎ±Ï„Î­ÏƒÏ„Î· Î´Ï…Î½Î±Ï„ÏŒÏ‚ Î¿ ÎµÎ¼Ï€Î»Î¿Ï…Ï„Î¹ÏƒÎ¼ÏŒÏ‚ Î±Ï€ÏŒ Î’Î®Î¼Î± 6 ({_e}). Î˜Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸Î¿ÏÎ½ Î¼ÏŒÎ½Î¿ ÎŸÎÎŸÎœÎ‘/Î¤ÎœÎ—ÎœÎ‘.")

    def auto_rename_columns(df: pd.DataFrame):
        mapping = {}
        if "Î¦Î™Î›ÎŸÎ™" not in df.columns:
            for c in df.columns:
                if "Î¦Î™Î›" in str(c).upper():
                    mapping[c] = "Î¦Î™Î›ÎŸÎ™"
                    break
        if "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—" not in df.columns and "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î•Î™Î£" in df.columns:
            mapping["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î•Î™Î£"] = "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—"
        return df.rename(columns=mapping), mapping
    
    used_df, rename_map = auto_rename_columns(used_df)

    def _strip_diacritics(s: str) -> str:
        nfkd = unicodedata.normalize("NFD", s)
        return "".join(ch for ch in nfkd if not unicodedata.combining(ch))
    
    def _canon_name(s: str) -> str:
        s = (str(s) if s is not None else "").strip()
        s = s.strip("[]'\" ")
        s = re.sub(r"\s+", " ", s)
        s = _strip_diacritics(s).upper()
        return s
    
    def _tokenize_name(canon: str):
        return [t for t in re.split(r"[^A-Z0-9]+", canon) if t]
    
    def _best_name_match(target_canon: str, candidates: list[str]) -> str | None:
        if target_canon in candidates:
            return target_canon
        tks = set(_tokenize_name(target_canon))
        if not tks:
            return None
        best = None; best_score = 0.0
        for c in candidates:
            cks = set(_tokenize_name(c))
            if not cks:
                continue
            inter = tks & cks
            jacc = len(inter) / max(1, len(tks | cks))
            prefix = any(c.startswith(tok) or target_canon.startswith(tok) for tok in inter) if inter else False
            score = jacc + (0.2 if prefix else 0.0)
            if score > best_score:
                best = c; best_score = score
        if best_score >= 0.34:
            return best
        return None

    def compute_conflict_counts_and_names(df: pd.DataFrame):
        if "ÎŸÎÎŸÎœÎ‘" not in df.columns or "Î¤ÎœÎ—ÎœÎ‘" not in df.columns:
            return pd.Series([0]*len(df), index=df.index), pd.Series([""]*len(df), index=df.index)
        if "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—" not in df.columns:
            return pd.Series([0]*len(df), index=df.index), pd.Series([""]*len(df), index=df.index)
        df = df.copy()
        df["__C"] = df["ÎŸÎÎŸÎœÎ‘"].map(_canon_name)
        cls = df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()
        canon_names = list(df["__C"].astype(str).unique())
        index_by = {cn: i for i, cn in enumerate(df["__C"])}
        def parse_targets(cell):
            raw = str(cell) if cell is not None else ""
            parts = [p.strip() for p in re.split(r"[;,/|\n]", raw) if p.strip()]
            return [_canon_name(p) for p in parts]
        counts = [0]*len(df); names = [""]*len(df)
        for i, row in df.iterrows():
            my_class = cls.iloc[i]
            targets = parse_targets(row.get("Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—",""))
            same = []
            for t in targets:
                j = index_by.get(t)
                if j is None:
                    match = _best_name_match(t, canon_names)
                    j = index_by.get(match) if match else None
                if j is not None and cls.iloc[j] == my_class and df.loc[i, "__C"] != df.loc[j, "__C"]:
                    same.append(df.loc[j, "ÎŸÎÎŸÎœÎ‘"])
            counts[i] = len(same)
            names[i] = ", ".join(same)
        return pd.Series(counts, index=df.index), pd.Series(names, index=df.index)

    def list_broken_mutual_pairs(df: pd.DataFrame) -> pd.DataFrame:
        fcol = next((c for c in ["Î¦Î™Î›ÎŸÎ™","Î¦Î™Î›ÎŸÎ£","Î¦Î™Î›Î™Î‘"] if c in df.columns), None)
        if fcol is None or "ÎŸÎÎŸÎœÎ‘" not in df.columns or "Î¤ÎœÎ—ÎœÎ‘" not in df.columns:
            return pd.DataFrame(columns=["A","A_Î¤ÎœÎ—ÎœÎ‘","B","B_Î¤ÎœÎ—ÎœÎ‘"])
        df = df.copy()
        df["__C"] = df["ÎŸÎÎŸÎœÎ‘"].map(_canon_name)
        name_to_original = dict(zip(df["__C"], df["ÎŸÎÎŸÎœÎ‘"].astype(str)))
        class_by_name = dict(zip(df["__C"], df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()))
        canon_names = list(df["__C"].astype(str).unique())
        def parse_list(cell):
            raw = str(cell) if cell is not None else ""
            parts = [p.strip() for p in re.split(r"[;,/|\n]", raw) if p.strip()]
            return [_canon_name(p) for p in parts]
        friends_map = {}
        for i, cn in enumerate(df["__C"]):
            raw_targets = parse_list(df.loc[i, fcol])
            resolved = []
            for t in raw_targets:
                if t in canon_names:
                    resolved.append(t)
                else:
                    match = _best_name_match(t, canon_names)
                    if match:
                        resolved.append(match)
            friends_map[cn] = set(resolved)
        rows = []
        for a, fa in friends_map.items():
            for b in fa:
                fb = friends_map.get(b, set())
                if a in fb and class_by_name.get(a) != class_by_name.get(b):
                    rows.append({
                        "A": name_to_original.get(a, a), "A_Î¤ÎœÎ—ÎœÎ‘": class_by_name.get(a,""),
                        "B": name_to_original.get(b, b), "B_Î¤ÎœÎ—ÎœÎ‘": class_by_name.get(b,"")
                    })
        return pd.DataFrame(rows).drop_duplicates()

    def generate_stats(df: pd.DataFrame) -> pd.DataFrame:
        df = df.copy()
        if "Î¤ÎœÎ—ÎœÎ‘" in df:
            df["Î¤ÎœÎ—ÎœÎ‘"] = df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()
        boys = df[df.get("Î¦Î¥Î›ÎŸ","").astype(str).str.upper().eq("Î‘")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¦Î¥Î›ÎŸ" in df else pd.Series(dtype=int)
        girls = df[df.get("Î¦Î¥Î›ÎŸ","").astype(str).str.upper().eq("Îš")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¦Î¥Î›ÎŸ" in df else pd.Series(dtype=int)
        edus = df[df.get("Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥" in df else pd.Series(dtype=int)
        z = df[df.get("Î–Î©Î—Î¡ÎŸÎ£","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î–Î©Î—Î¡ÎŸÎ£" in df else pd.Series(dtype=int)
        id_ = df[df.get("Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘" in df else pd.Series(dtype=int)
        g = df[df.get("ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î" in df else pd.Series(dtype=int)
        total = df.groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¤ÎœÎ—ÎœÎ‘" in df else pd.Series(dtype=int)

        try:
            c_counts, _ = compute_conflict_counts_and_names(df)
            cls = df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()
            conf_by_class = c_counts.groupby(cls).sum().astype(int)
        except Exception:
            conf_by_class = pd.Series(dtype=int)

        try:
            pairs = list_broken_mutual_pairs(df)
            if pairs.empty:
                broken = pd.Series({tm: 0 for tm in df["Î¤ÎœÎ—ÎœÎ‘"].dropna().astype(str).str.strip().unique()})
            else:
                counts = {}
                for _, row in pairs.iterrows():
                    counts[row["A_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["A_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
                    counts[row["B_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["B_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
                broken = pd.Series(counts).astype(int)
        except Exception:
            broken = pd.Series(dtype=int)

        stats = pd.DataFrame({
            "Î‘Î“ÎŸÎ¡Î™Î‘": boys,
            "ÎšÎŸÎ¡Î™Î¤Î£Î™Î‘": girls,
            "Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥": edus,
            "Î–Î©Î—Î¡ÎŸÎ™": z,
            "Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘": id_,
            "Î“ÎÎ©Î£Î— Î•Î›Î›Î—ÎÎ™ÎšÎ©Î": g,
            "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—": conf_by_class,
            "Î£Î Î‘Î£ÎœÎ•ÎÎ— Î¦Î™Î›Î™Î‘": broken,
            "Î£Î¥ÎÎŸÎ›ÎŸ ÎœÎ‘Î˜Î—Î¤Î©Î": total,
        }).fillna(0).astype(int)

        try:
            stats = stats.sort_index(key=lambda x: x.str.extract(r"(\d+)")[0].astype(float))
        except Exception:
            stats = stats.sort_index()
        return stats

    def export_stats_to_excel(stats_df: pd.DataFrame) -> BytesIO:
        output = BytesIO()
        with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
            stats_df.to_excel(writer, index=True, sheet_name="Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬", index_label="Î¤ÎœÎ—ÎœÎ‘")
            wb = writer.book; ws = writer.sheets["Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬"]
            header_fmt = wb.add_format({"bold": True, "valign":"vcenter", "text_wrap": True, "border":1})
            for col_idx, value in enumerate(["Î¤ÎœÎ—ÎœÎ‘"] + list(stats_df.columns)):
                ws.write(0, col_idx, value, header_fmt)
            for i in range(0, len(stats_df.columns)+1):
                ws.set_column(i, i, 18)
        output.seek(0)
        return output

    tab1, tab2, tab3 = st.tabs([
        "ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ (1 sheet)",
        "âŒ Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ (ÏŒÎ»Î± Ï„Î± sheets) â€” ÎˆÎ¾Î¿Î´Î¿Ï‚: Î Î»Î®ÏÎµÏ‚ Î±Î½Ï„Î¯Î³ÏÎ±Ï†Î¿ + Î£ÏÎ½Î¿ÏˆÎ·",
        "âš ï¸ ÎœÎ±Î¸Î·Ï„Î­Ï‚ Î¼Îµ ÏƒÏÎ³ÎºÏÎ¿Ï…ÏƒÎ· ÏƒÏ„Î·Î½ Î¯Î´Î¹Î± Ï„Î¬Î¾Î·",
    ])

    with tab1:
        st.subheader("ğŸ“ˆ Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ Î³Î¹Î± Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿ Sheet")
        st.selectbox("Î”Î¹Î¬Î»ÎµÎ¾Îµ sheet", ["FINAL_SCENARIO"], key="sheet_choice", index=0)
        with st.expander("ğŸ” Î”Î¹Î¬Î³Î½Ï‰ÏƒÎ·/ÎœÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯ÎµÏ‚", expanded=False):
            st.write("Î‘Ï…Ï„ÏŒÎ¼Î±Ï„ÎµÏ‚ Î¼ÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯ÎµÏ‚:", rename_map if rename_map else "â€”")
            required_cols = ["ÎŸÎÎŸÎœÎ‘","Î¦Î¥Î›ÎŸ","Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥","Î–Î©Î—Î¡ÎŸÎ£","Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘","ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î","Î¦Î™Î›ÎŸÎ™","Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—",]
            missing_cols = [c for c in required_cols if c not in used_df.columns]
            st.write("Î›ÎµÎ¯Ï€Î¿Ï…Î½ ÏƒÏ„Î®Î»ÎµÏ‚:", missing_cols if missing_cols else "â€”")
        if missing_cols:
            st.info("Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎµ/Î´Î¹ÏŒÏÎ¸Ï‰ÏƒÎµ Ï„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ Ï€Î¿Ï… Î»ÎµÎ¯Ï€Î¿Ï…Î½ ÏƒÏ„Î¿ Excel ÎºÎ±Î¹ Î¾Î±Î½Î±Ï†ÏŒÏÏ„Ï‰ÏƒÎ­ Ï„Î¿.")
        stats_df = generate_stats(used_df)
        st.dataframe(stats_df, use_container_width=True)
        st.download_button(
            "ğŸ“¥ Î•Î¾Î±Î³Ï‰Î³Î® ÎœÎŸÎÎŸ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ (Excel)",
            data=export_stats_to_excel(stats_df).getvalue(),
            file_name=f"statistika_STEP7_FINAL_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )

    with tab2:
        st.subheader("ğŸ’” Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ Ï†Î¹Î»Î¯ÎµÏ‚")
        pairs = list_broken_mutual_pairs(used_df)
        if pairs.empty:
            st.success("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÏ€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ Ï†Î¹Î»Î¯ÎµÏ‚.")
        else:
            st.dataframe(pairs, use_container_width=True)
            counts = {}
            for _, row in pairs.iterrows():
                counts[row["A_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["A_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
                counts[row["B_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["B_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
            summary = pd.DataFrame.from_dict(counts, orient="index", columns=["Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î‘Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚"]).sort_index()
            st.write("Î£ÏÎ½Î¿ÏˆÎ· Î±Î½Î¬ Ï„Î¼Î®Î¼Î±:")
            st.dataframe(summary, use_container_width=True)

    with tab3:
        st.subheader("âš ï¸ ÎœÎ±Î¸Î·Ï„Î­Ï‚ Î¼Îµ ÏƒÏÎ³ÎºÏÎ¿Ï…ÏƒÎ· ÏƒÏ„Î·Î½ Î¯Î´Î¹Î± Ï„Î¬Î¾Î·")
        counts, names = compute_conflict_counts_and_names(used_df)
        conflict_students = used_df.copy()
        conflict_students["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_Î Î›Î—Î˜ÎŸÎ£"] = counts.astype(int)
        conflict_students["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_ÎŸÎÎŸÎœÎ‘"] = names
        conflict_students = conflict_students.loc[conflict_students["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_Î Î›Î—Î˜ÎŸÎ£"] > 0, ["ÎŸÎÎŸÎœÎ‘","Î¤ÎœÎ—ÎœÎ‘","Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_Î Î›Î—Î˜ÎŸÎ£","Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_ÎŸÎÎŸÎœÎ‘"]]
        if conflict_students.empty:
            st.success("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÏ…Î³ÎºÏÎ¿ÏÏƒÎµÎ¹Ï‚ ÎµÎ½Ï„ÏŒÏ‚ Ï„Î·Ï‚ Î¯Î´Î¹Î±Ï‚ Ï„Î¬Î¾Î·Ï‚.")
        else:
            st.dataframe(conflict_students.sort_values(["Î¤ÎœÎ—ÎœÎ‘","ÎŸÎÎŸÎœÎ‘"]), use_container_width=True)

st.divider()

# ---------------------------
# ğŸ¯ ÎÎ•ÎŸ ÎšÎŸÎ¥ÎœÎ Î™: Î’Î­Î»Ï„Î¹ÏƒÏ„Î· ÎšÎ±Ï„Î±Î½Î¿Î¼Î® (Î’Î—ÎœÎ‘ 8)
# ---------------------------
if st.session_state.get("last_final_path"):
    st.header("ğŸ¯ Î’Î­Î»Ï„Î¹ÏƒÏ„Î· ÎšÎ±Ï„Î±Î½Î¿Î¼Î®")
    st.write("Î•Ï†Î±ÏÎ¼Î¿Î³Î® **Î’Î®Î¼Î±Ï„Î¿Ï‚ 8**: Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼Îµ asymmetric swaps Î³Î¹Î± Î¹ÏƒÎ¿ÎºÎ±Ï„Î±Î½Î¿Î¼Î® ÎµÏ€Î¯Î´Î¿ÏƒÎ·Ï‚, Ï†ÏÎ»Î¿Ï… ÎºÎ±Î¹ Î³Î½ÏÏƒÎ·Ï‚ ÎµÎ»Î»Î·Î½Î¹ÎºÏÎ½.")
    
    if st.button("ğŸ¯ Î’Î­Î»Ï„Î¹ÏƒÏ„Î· ÎšÎ±Ï„Î±Î½Î¿Î¼Î®", type="primary", use_container_width=True, key="run_step8"):
        try:
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Ï‰Î½ Î±ÏÏ‡ÎµÎ¯Ï‰Î½
            input_source = st.session_state.get("last_input_path")
            template_path = st.session_state.get("last_final_path")
            
            if not input_source or not Path(input_source).exists():
                st.error("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ Î±ÏÏ‡Î¹ÎºÏŒ Î±ÏÏ‡ÎµÎ¯Î¿ ÎµÎ¹ÏƒÏŒÎ´Î¿Ï…. Î¤ÏÎ­Î¾Îµ Ï€ÏÏÏ„Î± 'Î•ÎšÎ¤Î•Î›Î•Î£Î— ÎšÎ‘Î¤Î‘ÎÎŸÎœÎ—Î£'.")
            elif not template_path or not Path(template_path).exists():
                st.error("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ STEP7 template. Î¤ÏÎ­Î¾Îµ Ï€ÏÏÏ„Î± 'Î•ÎšÎ¤Î•Î›Î•Î£Î— ÎšÎ‘Î¤Î‘ÎÎŸÎœÎ—Î£'.")
            else:
                st.info(f"ğŸ“‚ Source: {Path(input_source).name}")
                st.info(f"ğŸ“‚ Template: {Path(template_path).name}")
                
                # Load step8 module
                s8 = _load_module("step8_fixed_final", ROOT / "step8_fixed_final.py")
                
                processor = s8.UnifiedProcessor()
                
                # Phase 1: Fill
                with st.spinner("ğŸ“‹ Phase 1/2: Filling template..."):
                    processor.read_source_data(str(input_source))
                    temp_filled = ROOT / _timestamped("STEP8_TEMP_FILLED", ".xlsx")
                    processor.fill_target_excel(str(template_path), str(temp_filled))
                    st.success(f"âœ… Phase 1 Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ: {len(processor.students_data)} Î¼Î±Î¸Î·Ï„Î­Ï‚")
                
                # Phase 2: Optimize
                with st.spinner("ğŸ¯ Phase 2/2: Optimizing..."):
                    processor.load_filled_data(str(temp_filled))
                    
                    spreads_before = processor.calculate_spreads()
                    st.write("**ğŸ“Š Î Î¡Î™Î Ï„Î·Î½ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·:**")
                    st.write(f"- EP3 spread: {spreads_before['ep3']}")
                    st.write(f"- Boys spread: {spreads_before['boys']}")
                    st.write(f"- Girls spread: {spreads_before['girls']}")
                    st.write(f"- Greek spread: {spreads_before['greek_yes']}")
                    
                    swaps, spreads_after = processor.optimize(max_iterations=100)
                    
                    st.write("**ğŸ“Š ÎœÎ•Î¤Î‘ Ï„Î· Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·:**")
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("EP3 spread", spreads_after['ep3'], 
                                 delta=spreads_after['ep3'] - spreads_before['ep3'],
                                 delta_color="inverse")
                    with col2:
                        st.metric("Boys spread", spreads_after['boys'],
                                 delta=spreads_after['boys'] - spreads_before['boys'],
                                 delta_color="inverse")
                    with col3:
                        st.metric("Girls spread", spreads_after['girls'],
                                 delta=spreads_after['girls'] - spreads_before['girls'],
                                 delta_color="inverse")
                    with col4:
                        st.metric("Greek spread", spreads_after['greek_yes'],
                                 delta=spreads_after['greek_yes'] - spreads_before['greek_yes'],
                                 delta_color="inverse")
                    
                    # Export
                    final_optimized = ROOT / _timestamped("STEP8_OPTIMIZED", ".xlsx")
                    processor.export_optimized_excel(swaps, spreads_after, str(final_optimized))
                    
                    # Cleanup temp
                    temp_filled.unlink(missing_ok=True)
                    
                    st.success(f"ğŸ‰ ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ! Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ {len(swaps)} swaps ÎµÏ†Î±ÏÎ¼ÏŒÏƒÏ„Î·ÎºÎ±Î½.")
                    
                    # Display warnings
                    if processor.warnings:
                        with st.expander(f"âš ï¸ {len(processor.warnings)} warnings", expanded=False):
                            for w in processor.warnings[:20]:
                                st.caption(w)
                    
                    # Download button
                    st.download_button(
                        "â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ Î’Î•Î›Î¤Î™Î£Î¤ÎŸÎ ÎŸÎ™Î—ÎœÎ•ÎÎŸ Î‘Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î± (Î’Î®Î¼Î± 8)",
                        data=_read_file_bytes(final_optimized),
                        file_name=final_optimized.name,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True,
                        key="dl_step8"
                    )
                    
        except Exception as e:
            st.exception(e)

st.divider()

# ---------------------------
# â™»ï¸ Î•Ï€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ· (Î¼Î¯Î± ÎºÎ±Î¹ ÎºÎ±Î»Î®)
# ---------------------------
st.header("â™»ï¸ Î•Ï€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ·")
st.write("ÎšÎ±Î¸Î±ÏÎ¯Î¶ÎµÎ¹ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎºÎ±Î¹ Î¾Î±Î½Î±Ï†Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿ app.")
if st.button("â™»ï¸ Î•Ï€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ· Ï„ÏÏÎ±", type="secondary", use_container_width=True, key="restart_btn"):
    _restart_app()

st.divider()
